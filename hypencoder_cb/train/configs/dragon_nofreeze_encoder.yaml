model_config:
  checkpoint_path: jfkback/hypencoder.6_layer
  tokenizer_pretrained_model_name_or_path: facebook/dragon-plus-query-encoder
  query_encoder_kwargs:
    model_name_or_path: facebook/dragon-plus-query-encoder
    freeze_transformer: false
    embedding_representation: null
    base_encoder_output_dim: 768
    converter_kwargs:
      vector_dimensions: [768, 768, 768, 768, 768, 768, 768, 1]
      activation_type: relu
      do_residual_on_last: false
  passage_encoder_kwargs:
    model_name_or_path: facebook/dragon-plus-context-encoder
    freeze_transformer: false
    pooling_type: cls   # TAS-B still uses CLS output internally
  shared_encoder: false
  loss_type:
    - margin_mse
    - cross_entropy
  loss_kwargs:
    - {}
    - {"use_in_batch_negatives": true, "only_use_first_item": true}
data_config:
  training_data_jsonl: /scratch-shared/scur1744/tokenized_dragon.jsonl
  validation_data_jsonl: null
  positive_filter_type: first
  label_key: score
  num_positives_to_sample: 1
  num_negatives_to_sample: 7
trainer_config:
  hf_trainer_config:
    output_dir: /scratch-shared/scur1744/models/dragon_nofreeze
    overwrite_output_dir: true #Changed
    remove_unused_columns: false
    eval_strategy: 'no'
    per_device_train_batch_size: 32
    per_device_eval_batch_size: 32
    gradient_accumulation_steps: 2
    dataloader_prefetch_factor: 5
    dataloader_num_workers: 8
    dataloader_persistent_workers: false
    learning_rate: 1e-5 #Changed 
    weight_decay: 0.01 #Changed
    num_train_epochs: 3 #Changed
    lr_scheduler_type: linear #Changed
    warmup_ratio: 0.1 #changed
    warmup_steps: 0 #Changed
    logging_strategy: steps
    logging_steps: 10
    max_steps: -1
    save_strategy: steps
    save_steps: 2500
    save_total_limit: null
    save_only_model: false
    bf16: true
    tf32: true
    fp16: false
    run_name: "hypencoder.dragon_nofreeze" #Changed
    disable_tqdm: true
    ddp_find_unused_parameters: true
    fsdp: ''
    fsdp_config: null
    report_to: none
    push_to_hub: false
    hub_model_id: null
    hub_strategy: every_save
    hub_private_repo: true
    gradient_checkpointing: false
    save_safetensors: false
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1.0e-08
    torch_compile: false
  resume_from_checkpoint: false #Changed
