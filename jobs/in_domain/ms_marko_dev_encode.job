#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=encode_ms_marco_dev
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=24:00:00
#SBATCH --output=outputs/encode_ms_marco_dev_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2

source activate hype

export MODEL_NAME_OR_PATH="jfkback/hypencoder.6_layer"        # from huggingface using from_pretrained
export ENCODING_PATH="$HOME/hypencoder/encoded_items/msmarco-passage-dev"    # path to save encoded items
mkdir -p "$ENCODING_PATH"

srun python -u hypencoder_cb/inference/encode.py \
  --model_name_or_path="$MODEL_NAME_OR_PATH" \
  --output_path="$ENCODING_PATH" \
  --ir_dataset_name="msmarco-passage/dev/small"                          # from huggingface, downloaded into .ir_datasets