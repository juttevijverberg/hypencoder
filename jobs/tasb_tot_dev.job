#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=tasb_tot_dev
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --mem=64G
#SBATCH --time=02:00:00
#SBATCH --output=outputs/tasb_tot_dev_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2

source activate hype


export MODEL_NAME_OR_PATH="sentence-transformers/msmarco-distilbert-base-tas-b"
export ENCODING_PATH="$HOME/hypencoder/encoded_items/msmarco-passage-dev"
export RETRIEVAL_DIR="$HOME/hypencoder/retrieval_outputs/msmarco-passage-dev"
export IR_DATASET_NAME="trec-tot/2023/dev"


python scripts/evaluate_tasb.py \
  --model_name=$MODEL_NAME_OR_PATH \
  --encoded_item_path=$ENCODING_PATH \
  --ir_dataset_name=$IR_DATASET_NAME \
  --output_dir=$RETRIEVAL_DIR \
  --top_k=1000 \
  --batch_size=64 