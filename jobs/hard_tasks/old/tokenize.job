#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=tokenize
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=10:00:00
#SBATCH --output=outputs/tokenize.out

module purge
module load 2023
module load Anaconda3/2023.07-2

source activate hype

python hypencoder_cb/utils/tokenizer_utils.py \
    --standard_format_jsonl=data/tot/train/all.standard.jsonl \
    --output_file=data/tot/train/tokenized_data.jsonl \
    --tokenizer="google-bert/bert-base-uncased" \
    --add_special_tokens=True \
    --query_max_length=32 \
    --item_max_length=512 

python hypencoder_cb/utils/tokenizer_utils.py \
    --standard_format_jsonl=data/msmarco_with_instructions/standard/train.all_queries.jsonl \
    --output_file=data/msmarco_with_instructions/standard/tokenized.jsonl \
    --tokenizer="google-bert/bert-base-uncased" \
    --add_special_tokens=True \
    --query_max_length=32 \
    --item_max_length=512 
