#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=hard_task_encode
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=02:00:00
#SBATCH --output=outputs/hard_task_encode.out

module purge
module load 2023
module load Anaconda3/2023.07-2

source activate hype

#rm -f "$HOME/encoded_items/trec-dl-hard.docs.tmp" "$HOME/encoded_items/trec-dl-hard.docs"

export MODEL_NAME_OR_PATH="jfkback/hypencoder.6_layer"                  # from huggingface using from_pretrained
export ENCODING_PATH="$HOME/hypencoder/encoded_items/trec-dl-hard"      # path to save encoded items
mkdir -p "$ENCODING_PATH"

# Dataset names: disks45/nocr/trec-robust-2004, trec-core-2017, trec-news-2021

python hypencoder_cb/inference/encode.py \
  --model_name_or_path="$MODEL_NAME_OR_PATH" \
  --output_path="$ENCODING_PATH" \
  --ir_dataset_name="msmarco-passage/trec-dl-hard"        # from huggingface, downloaded into .ir_datasets
